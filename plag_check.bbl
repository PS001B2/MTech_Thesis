% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{dastgerdi_investigating_2022}{article}{}
      \name{author}{2}{}{%
        {{hash=0288cdae1896eb3a25891ab5b4303352}{%
           family={Dastgerdi},
           familyi={D\bibinitperiod},
           given={Amin\bibnamedelima Karimi},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=b962bb6b4e97a88576426c1545649b95}{%
           family={Mercorelli},
           familyi={M\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{87f38dd604f46996dc5984c1f25e5a08}
      \strng{fullhash}{87f38dd604f46996dc5984c1f25e5a08}
      \strng{bibnamehash}{87f38dd604f46996dc5984c1f25e5a08}
      \strng{authorbibnamehash}{87f38dd604f46996dc5984c1f25e5a08}
      \strng{authornamehash}{87f38dd604f46996dc5984c1f25e5a08}
      \strng{authorfullhash}{87f38dd604f46996dc5984c1f25e5a08}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Predicting financial markets is of particular importance for investors who intend to make the most profit. Analysing reasonable and precise strategies for predicting financial markets has a long history. Deep learning techniques include analyses and predictions that can assist scientists in discovering unknown patterns of data. In this project, application of noise elimination techniques such as Wavelet transform and Kalman filter in combination of deep learning methods were discussed for predicting financial time series. The results show employing noise elimination techniques such as Wavelet transform and Kalman filter, have considerable effect on performance of {LSTM} neural network in extracting hidden patterns in the financial time series and can precisely predict future actions in these markets.}
      \field{day}{18}
      \field{issn}{2224-2899, 1109-9526}
      \field{journaltitle}{{WSEAS} {TRANSACTIONS} {ON} {BUSINESS} {AND} {ECONOMICS}}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{Investigating the Effect of Noise Elimination on {LSTM} Models for Financial Markets Prediction Using Kalman Filter and Wavelet Transform}
      \field{urlday}{10}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{432\bibrangedash 441}
      \range{pages}{10}
      \verb{doi}
      \verb 10.37394/23207.2022.19.39
      \endverb
      \verb{file}
      \verb Dastgerdi and Mercorelli - 2022 - Investigating the Effect of Noise Elimination on L.pdf:/Users/sharmaparth/Zotero/storage/NKBTBRRU/Dastgerdi and Mercorelli - 2022 - Investigating the Effect of Noise Elimination on L.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://wseas.com/journals/bae/2022/a765107-015(2022).pdf
      \endverb
      \verb{url}
      \verb https://wseas.com/journals/bae/2022/a765107-015(2022).pdf
      \endverb
    \endentry
    \entry{fang_kalman-lstm_2021}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=8eb3d74f259ea9d828722569886126b9}{%
           family={Fang},
           familyi={F\bibinitperiod},
           given={Weiwei},
           giveni={W\bibinitperiod}}}%
        {{hash=0e703cc8b8319d9f832635db7b75c6a6}{%
           family={Cai},
           familyi={C\bibinitperiod},
           given={Weihong},
           giveni={W\bibinitperiod}}}%
        {{hash=c5f3b172e37fb63da9110d47079b0bed}{%
           family={Fan},
           familyi={F\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=77688efd72442dcafdc517067f583307}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Jingwen},
           giveni={J\bibinitperiod}}}%
        {{hash=fe5956745bc4d1abf288b0606f086283}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Teng},
           giveni={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Chongqing, China}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{b05296168368ec9d5b65884a30397a2e}
      \strng{fullhash}{e7b029da6adabcfb7d8583619ae1926f}
      \strng{bibnamehash}{e7b029da6adabcfb7d8583619ae1926f}
      \strng{authorbibnamehash}{e7b029da6adabcfb7d8583619ae1926f}
      \strng{authornamehash}{b05296168368ec9d5b65884a30397a2e}
      \strng{authorfullhash}{e7b029da6adabcfb7d8583619ae1926f}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper proposes a time prediction model based on Kalman filtering and {LSTM}, namely the Kalman {LSTM} model, which is used to predict time series data with long-term and short-term characteristics. The {KalmanLSTM} model uses {LSTM}'s unique storage function to "store" the information contained in the pre-order data. It is then used to obtain the basic time series of the prediction problem in subsequent processing. The following Kalman filter model dynamically adjusts the basic time data series obtained by {LSTM} processing. Finally, we will obtain adjusted forecasts. Here, we establish training and test set samples to train the Kalman-{LSTM} model and test the performance of the sample model. For comparison, we evaluated the {RMSE} (root mean square error) indicator of the conventional {LSTM} model with the Kalman-{LSTM} model. The results show that the Kalman-{LSTM} model is superior to the {LSTM} model, and can get more accurate predictions.}
      \field{booktitle}{2021 {IEEE} 5th Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC})}
      \field{day}{12}
      \field{eventtitle}{2021 {IEEE} 5th Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC})}
      \field{isbn}{978-1-72818-028-1}
      \field{langid}{english}
      \field{month}{3}
      \field{title}{Kalman-{LSTM} Model for Short-term Traffic Flow Forecasting}
      \field{urlday}{11}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1604\bibrangedash 1608}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/IAEAC50856.2021.9390991
      \endverb
      \verb{file}
      \verb Fang et al. - 2021 - Kalman-LSTM Model for Short-term Traffic Flow Fore.pdf:/Users/sharmaparth/Zotero/storage/CQN4PUKS/Fang et al. - 2021 - Kalman-LSTM Model for Short-term Traffic Flow Fore.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9390991/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9390991/
      \endverb
    \endentry
    \entry{song_improved_2022}{article}{}
      \name{author}{6}{}{%
        {{hash=0f9c80f21ac9c39660b31815b6f31282}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Fei},
           giveni={F\bibinitperiod}}}%
        {{hash=78be8ea0cb80e4e1b59bf06100942e90}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yong},
           giveni={Y\bibinitperiod}}}%
        {{hash=6daab9c045b3d0fc9e6183326e04b8ff}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Wei},
           giveni={W\bibinitperiod}}}%
        {{hash=49dfd7053196f7046e8a1bdb7ddda734}{%
           family={Dong},
           familyi={D\bibinitperiod},
           given={Limeng},
           giveni={L\bibinitperiod}}}%
        {{hash=58065c26fafb44d1f9bff473a1c3ee61}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Minqi},
           giveni={M\bibinitperiod}}}%
        {{hash=c82a1e79240e212fea2d08782a673906}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Junfang},
           giveni={J\bibinitperiod}}}%
      }
      \name{editor}{1}{}{%
        {{hash=8405c5e3310cb2cca478dc560491682c}{%
           family={Alamoodi},
           familyi={A\bibinitperiod},
           given={A.H.},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{08e0186b47e3cfaea841205a3231f076}
      \strng{fullhash}{b80e87fbbb43336db6e83caa158a8e20}
      \strng{bibnamehash}{b80e87fbbb43336db6e83caa158a8e20}
      \strng{authorbibnamehash}{b80e87fbbb43336db6e83caa158a8e20}
      \strng{authornamehash}{08e0186b47e3cfaea841205a3231f076}
      \strng{authorfullhash}{b80e87fbbb43336db6e83caa158a8e20}
      \strng{editorbibnamehash}{8405c5e3310cb2cca478dc560491682c}
      \strng{editornamehash}{8405c5e3310cb2cca478dc560491682c}
      \strng{editorfullhash}{8405c5e3310cb2cca478dc560491682c}
      \field{sortinit}{5}
      \field{sortinithash}{20e9b4b0b173788c5dace24730f47d8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The target tracking of nonlinear maneuvering radar in dense clutter environments is still an important but difficult problem to be solved effectively. Traditional solutions often rely on motion models and prior distributions. This paper presents a novel improved architecture of Kalman filter based on a recursive neural network, which combines the sequence learning of recurrent neural networks with the precise prediction of Kalman filter in an end-to-end manner. We employ three {LSTM} networks to model nonlinear motion equation, motion noise, and measurement noise, respectively, and learn their long-term dependence from a large amount of training data. They are then applied to the prediction and update process of Kalman filter to calculate the estimated target state. Our approach is able to address the tracking problem of nonlinear maneuvering radar target online end-to-end and does not require the motion models and prior distributions. Experimental results show that our method is more effective and faster than the traditional methods and more accurate than the method with {LSTM} network alone.}
      \field{day}{21}
      \field{issn}{1530-8677, 1530-8669}
      \field{journaltitle}{Wireless Communications and Mobile Computing}
      \field{langid}{english}
      \field{month}{8}
      \field{shortjournal}{Wireless Communications and Mobile Computing}
      \field{title}{An Improved Kalman Filter Based on Long Short-Memory Recurrent Neural Network for Nonlinear Radar Target Tracking}
      \field{urlday}{11}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2022}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 10}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1155/2022/8280428
      \endverb
      \verb{file}
      \verb Song et al. - 2022 - An Improved Kalman Filter Based on Long Short-Memo.pdf:/Users/sharmaparth/Zotero/storage/Q3973LNR/Song et al. - 2022 - An Improved Kalman Filter Based on Long Short-Memo.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.hindawi.com/journals/wcmc/2022/8280428/
      \endverb
      \verb{url}
      \verb https://www.hindawi.com/journals/wcmc/2022/8280428/
      \endverb
    \endentry
    \entry{tian_application_2024}{article}{}
      \name{author}{6}{}{%
        {{hash=fdfee2e3c1c068d2dd528460b5a1cc60}{%
           family={Tian},
           familyi={T\bibinitperiod},
           given={Yalin},
           giveni={Y\bibinitperiod}}}%
        {{hash=d767fc417881d8ac11b2874af766e8bb}{%
           family={Lian},
           familyi={L\bibinitperiod},
           given={Zengzeng},
           giveni={Z\bibinitperiod}}}%
        {{hash=4594190fbd4a3e1a20f19b096b6abb62}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Penghui},
           giveni={P\bibinitperiod}}}%
        {{hash=df8cd231ad43703a53dd3a0794f7cae1}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Mengqi},
           giveni={M\bibinitperiod}}}%
        {{hash=399f3d8770e8f8421e4eec452bc8b520}{%
           family={Yue},
           familyi={Y\bibinitperiod},
           given={Zhe},
           giveni={Z\bibinitperiod}}}%
        {{hash=22da5948a22101f06b86f1a848e64321}{%
           family={Chai},
           familyi={C\bibinitperiod},
           given={Huabin},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{1c47c20e0901b6b1e48c0bef928245ca}
      \strng{fullhash}{1000fc21aa0bcf7b25213512a7a1f8fd}
      \strng{bibnamehash}{1000fc21aa0bcf7b25213512a7a1f8fd}
      \strng{authorbibnamehash}{1000fc21aa0bcf7b25213512a7a1f8fd}
      \strng{authornamehash}{1c47c20e0901b6b1e48c0bef928245ca}
      \strng{authorfullhash}{1000fc21aa0bcf7b25213512a7a1f8fd}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Abstract Ultra-wideband technology has good anti-interference capabilities and development prospects in indoor positioning. Since ultra-wideband will be affected by random errors in indoor positioning, to exploit the advantages of the Kalman filter ({KF}) and the long short-term memory ({LSTM}) network, this paper proposes a long short-term memory neural network algorithm fused with the Kalman filter ({KF}–{LSTM}) to improve {UWB} positioning. First, the ultra-wideband data is processed through {KF} to weaken the noise in the data, and then the data is fed into the {LSTM} network for training, and the capability of the {LSTM} network to process time series features is employed to obtain more accurate label positions. Finally, simulation and measurement results show that the {KF}–{LSTM} algorithm achieves 71.31\%, 37.28\%, and 49.31\% higher average positioning accuracy than the back propagation ({BP}) network, (back propagation network fused with the Kalman filter ({KF}-{BP}), and {LSTM} network algorithms, respectively, and the {KF}–{LSTM} algorithm performs more stably. Meanwhile, the more noise the data contains, the more obvious the stability contrast between the four algorithms.}
      \field{day}{22}
      \field{issn}{2045-2322}
      \field{journaltitle}{Scientific Reports}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Sci Rep}
      \field{title}{Application of a long short-term memory neural network algorithm fused with Kalman filter in {UWB} indoor positioning}
      \field{urlday}{11}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{14}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1925}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1038/s41598-024-52464-y
      \endverb
      \verb{file}
      \verb Tian et al. - 2024 - Application of a long short-term memory neural net.pdf:/Users/sharmaparth/Zotero/storage/EZL4YTR5/Tian et al. - 2024 - Application of a long short-term memory neural net.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.nature.com/articles/s41598-024-52464-y
      \endverb
      \verb{url}
      \verb https://www.nature.com/articles/s41598-024-52464-y
      \endverb
    \endentry
    \entry{wang_hybrid_2024}{misc}{}
      \name{author}{4}{}{%
        {{hash=42111461efe014b53b28e65eb7dd3ed4}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Chunsheng},
           giveni={C\bibinitperiod}}}%
        {{hash=9ee26751f49d06f4e9489bdceb89555a}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Ripeng},
           giveni={R\bibinitperiod}}}%
        {{hash=2923de2da7f9b32b957552e414b6bc16}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Yuan},
           giveni={Y\bibinitperiod}}}%
        {{hash=fe891ec1caaae1c82d39c8783ae1c36a}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Mutian},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{73b022eba262c6fb75b8d1ad692633c6}
      \strng{fullhash}{dd16405c007396f685979b9a06747b38}
      \strng{bibnamehash}{dd16405c007396f685979b9a06747b38}
      \strng{authorbibnamehash}{dd16405c007396f685979b9a06747b38}
      \strng{authornamehash}{73b022eba262c6fb75b8d1ad692633c6}
      \strng{authorfullhash}{dd16405c007396f685979b9a06747b38}
      \field{sortinit}{9}
      \field{sortinithash}{0a5ebc79d83c96b6579069544c73c7d4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{A Hybrid Model for State of Charge Estimation of Lithium-Ion Batteries Utilizing Improved Adaptive Extended Kalman Filter and Long Short-Term Memory Neural Network}
      \field{urlday}{5}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.2139/ssrn.4834979
      \endverb
      \verb{file}
      \verb Wang et al. - 2024 - A Hybrid Model for State of Charge Estimation of L.pdf:/Users/sharmaparth/Zotero/storage/7I78P7Z5/Wang et al. - 2024 - A Hybrid Model for State of Charge Estimation of L.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ssrn.com/abstract=4834979
      \endverb
      \verb{url}
      \verb https://www.ssrn.com/abstract=4834979
      \endverb
    \endentry
    \entry{sahni_neoteric_2022}{incollection}{}
      \name{author}{3}{}{%
        {{hash=619c6fad523ab210c7a286fc5671f1c9}{%
           family={Shah},
           familyi={S\bibinitperiod},
           given={Hetvi},
           giveni={H\bibinitperiod}}}%
        {{hash=8af8f1b4a33f1d1955b16e20a0878faa}{%
           family={Bhatt},
           familyi={B\bibinitperiod},
           given={Vishva},
           giveni={V\bibinitperiod}}}%
        {{hash=e126922374eceb691b9a36094341b723}{%
           family={Shah},
           familyi={S\bibinitperiod},
           given={Jigarkumar},
           giveni={J\bibinitperiod}}}%
      }
      \name{editor}{4}{}{%
        {{hash=a55840837ce06408e0a8c0f7155080da}{%
           family={Sahni},
           familyi={S\bibinitperiod},
           given={Manoj},
           giveni={M\bibinitperiod}}}%
        {{hash=86ca126e46a1d17a8f14ea906e747cda}{%
           family={Merigó},
           familyi={M\bibinitperiod},
           given={José\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=226353b15eb8aede9e4ba028a1ad6e52}{%
           family={Sahni},
           familyi={S\bibinitperiod},
           given={Ritu},
           giveni={R\bibinitperiod}}}%
        {{hash=0a6e2dd2d1df1668e1fa6668c17598f7}{%
           family={Verma},
           familyi={V\bibinitperiod},
           given={Rajkumar},
           giveni={R\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Singapore}%
      }
      \list{publisher}{1}{%
        {Springer Singapore}%
      }
      \strng{namehash}{f646d30bee681ebce4a927ea32b395db}
      \strng{fullhash}{f646d30bee681ebce4a927ea32b395db}
      \strng{bibnamehash}{f646d30bee681ebce4a927ea32b395db}
      \strng{authorbibnamehash}{f646d30bee681ebce4a927ea32b395db}
      \strng{authornamehash}{f646d30bee681ebce4a927ea32b395db}
      \strng{authorfullhash}{f646d30bee681ebce4a927ea32b395db}
      \strng{editorbibnamehash}{59fdd05628b3ec5a4799e894fbd368e1}
      \strng{editornamehash}{509a046c95b6a2e9e9556bf1331a345b}
      \strng{editorfullhash}{59fdd05628b3ec5a4799e894fbd368e1}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Stock market time-series analysis and its price prediction have been intriguing the human mind ever since they were in existence. Analysis of time series with the help of various models has become imperative not only in business but also in every day stock market practices as algorithms improve the speed, accuracy, and discipline and one can always backtest these strategies to see the type of performance achieved in a real-time environment. Numerous models have been put forward to improve the accuracy and robustness in forecasting market prices. However, due to the high volatility and non-stationary nature of the stock market data, many of these models have been ineffective in forecasting future trends. Addition of artificial neural networks to such models would lead to giant leaps in this domain providing reliable and accurate models as the weights are assigned to the input parameters, are computed in the training phase and are adapted by learning with gradient descent and backpropagation algorithm. This paper proposes an aggregation of the novel autoregressive integrated moving average ({ARIMA}) model with the long short- term memory ({LSTM}) model to increase the forecasting accuracy by using the dynamism of neural networks, thereby generating the best-fitted coefficients for the model. The methodology of this model is then evaluated by comparing the empirical results with other conventional models on the Indian stock market data. Accordingly, it is observed that this model achieves significantly better forecasting accuracy and can alternatively be put forward to be used as a suitable model.}
      \field{booktitle}{Mathematical Modeling, Computational Intelligence Techniques and Renewable Energy}
      \field{isbn}{9789811659515 9789811659522}
      \field{langid}{english}
      \field{note}{Series Title: Advances in Intelligent Systems and Computing}
      \field{title}{A Neoteric Technique Using {ARIMA}-{LSTM} for Time Series Analysis on Stock Market Forecasting}
      \field{urlday}{31}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{volume}{1405}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{381\bibrangedash 392}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1007/978-981-16-5952-2_33
      \endverb
      \verb{file}
      \verb Shah et al. - 2022 - A Neoteric Technique Using ARIMA-LSTM for Time Ser.pdf:/Users/sharmaparth/Zotero/storage/SWQFQJZE/Shah et al. - 2022 - A Neoteric Technique Using ARIMA-LSTM for Time Ser.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-981-16-5952-2_33
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-981-16-5952-2_33
      \endverb
    \endentry
    \entry{yoon_time-series_2019}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=7b5738a87e11e248e9c5a24b5b0f0769}{%
           family={Yoon},
           familyi={Y\bibinitperiod},
           given={Jinsung},
           giveni={J\bibinitperiod}}}%
        {{hash=fbb5c34530a1390939addb679d25fb03}{%
           family={Jarrett},
           familyi={J\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {english}%
      }
      \strng{namehash}{22c0ebb4371728d4e5bdc3ad11306d68}
      \strng{fullhash}{22c0ebb4371728d4e5bdc3ad11306d68}
      \strng{bibnamehash}{22c0ebb4371728d4e5bdc3ad11306d68}
      \strng{authorbibnamehash}{22c0ebb4371728d4e5bdc3ad11306d68}
      \strng{authornamehash}{22c0ebb4371728d4e5bdc3ad11306d68}
      \strng{authorfullhash}{22c0ebb4371728d4e5bdc3ad11306d68}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction—which allow finer control over network dynamics—are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.}
      \field{booktitle}{Proceedings of the 33rd International Conference on Neural Information Processing Systems (NeurIPS)}
      \field{booktitleaddon}{NeurIPS}
      \field{month}{12}
      \field{note}{Article No.: 494}
      \field{title}{Time-series Generative Adversarial Networks}
      \field{year}{2019}
      \field{pages}{5508\bibrangedash 5518}
      \range{pages}{11}
      \verb{file}
      \verb Yoon and Jarrett - Time-series Generative Adversarial Networks.pdf:/Users/sharmaparth/Zotero/storage/HEEXX4IG/Yoon and Jarrett - Time-series Generative Adversarial Networks.pdf:application/pdf
      \endverb
    \endentry
    \entry{gu_ragic_2025}{article}{}
      \name{author}{3}{}{%
        {{hash=2814092662b70a2da07bc7f10591893a}{%
           family={Gu},
           familyi={G\bibinitperiod},
           given={Jingyi},
           giveni={J\bibinitperiod}}}%
        {{hash=8cc2a2483e466165b6cb2e6e56e0dac9}{%
           family={Du},
           familyi={D\bibinitperiod},
           given={Wenlu},
           giveni={W\bibinitperiod}}}%
        {{hash=094852ffd6f03ba54d3e17efd267837f}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Guiling},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{95bd4b1b25cb2adf8515c8497a6dbbaf}
      \strng{fullhash}{95bd4b1b25cb2adf8515c8497a6dbbaf}
      \strng{bibnamehash}{95bd4b1b25cb2adf8515c8497a6dbbaf}
      \strng{authorbibnamehash}{95bd4b1b25cb2adf8515c8497a6dbbaf}
      \strng{authornamehash}{95bd4b1b25cb2adf8515c8497a6dbbaf}
      \strng{authorfullhash}{95bd4b1b25cb2adf8515c8497a6dbbaf}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Efforts to predict stock market outcomes have yielded limited success due to the inherently stochastic nature of the market, inﬂuenced by numerous unpredictable factors. Many existing prediction approaches focus on single-point predictions, lacking the depth needed for effective decision-making and often overlooking market risk. To bridge this gap, we propose {RAGIC}, a novel riskaware framework for stock interval prediction to quantify uncertainty. Our approach leverages a Generative Adversarial Network ({GAN}) to produce future price sequences infused with randomness inherent in ﬁnancial markets. {RAGIC}’s generator detects the risk perception of informed investors and captures historical price trends globally and locally. Then the risk-sensitive intervals is built upon the simulated future prices from sequence generation through statistical inference, incorporating horizon-wise insights. The interval’s width is adaptively adjusted to reﬂect market volatility. Importantly, our approach relies solely on publicly available data and incurs only low computational overhead. {RAGIC}’s evaluation across globally recognized broad-based indices demonstrates its balanced performance, offering both accuracy and informativeness. Achieving a consistent 95\% coverage, {RAGIC} maintains a narrow interval width. This promising outcome suggests that our approach effectively addresses the challenges of stock market prediction while incorporating vital risk considerations.}
      \field{issn}{1041-4347, 1558-2191, 2326-3865}
      \field{journaltitle}{{IEEE} Transactions on Knowledge and Data Engineering}
      \field{langid}{english}
      \field{month}{4}
      \field{number}{4}
      \field{shortjournal}{{IEEE} Trans. Knowl. Data Eng.}
      \field{shorttitle}{{RAGIC}}
      \field{title}{{RAGIC}: Risk-Aware Generative Framework for Stock Interval Construction}
      \field{urlday}{11}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{37}
      \field{year}{2025}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2085\bibrangedash 2096}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/TKDE.2025.3533492
      \endverb
      \verb{file}
      \verb Gu et al. - 2025 - RAGIC Risk-Aware Generative Framework for Stock I.pdf:/Users/sharmaparth/Zotero/storage/E469YKD8/Gu et al. - 2025 - RAGIC Risk-Aware Generative Framework for Stock I.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/10885039/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/10885039/
      \endverb
    \endentry
    \entry{samanta_dual_2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=2d161ef85a9b6b4aeb4a91a925f3c9bb}{%
           family={Samanta},
           familyi={S\bibinitperiod},
           given={Subhrajit},
           giveni={S\bibinitperiod}}}%
        {{hash=7e7c73f50aa9ede6bdcdce28cc40498b}{%
           family={Pratama},
           familyi={P\bibinitperiod},
           given={Mahardhika},
           giveni={M\bibinitperiod}}}%
        {{hash=fba549dc1404dbe9d722aa24ceffe3b2}{%
           family={Sundaram},
           familyi={S\bibinitperiod},
           given={Suresh},
           giveni={S\bibinitperiod}}}%
        {{hash=397c14328c2484e16306c31d425db2b3}{%
           family={Srikanth},
           familyi={S\bibinitperiod},
           given={Narasimalu},
           giveni={N\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Glasgow, United Kingdom}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{5b1232e11bdce2d49f817bf1e011052e}
      \strng{fullhash}{ab9007f8ac0b96b571057263c60468fa}
      \strng{bibnamehash}{ab9007f8ac0b96b571057263c60468fa}
      \strng{authorbibnamehash}{ab9007f8ac0b96b571057263c60468fa}
      \strng{authornamehash}{5b1232e11bdce2d49f817bf1e011052e}
      \strng{authorfullhash}{ab9007f8ac0b96b571057263c60468fa}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{When it comes to time series forecasting, lag in the predicted sequence can be a predominant issue. Unfortunately, this is often overlooked in most of the time series literature as this does not contribute to a high prediction error (i.e. {MSE}). However, it leads to a rather poor forecast in terms of movement prediction in time series. In this article, we tackle this basic problem with a novel trend driven mechanism. Trend, deﬁned as the inherent pattern of the data, is extracted here and utilized next to perform a lag-free forecasting. We propose a generic and light Dual Network Solution ({DNS}), where the ﬁrst network predicts the trend and the second network utilizes that predicted trend along with its historical information to capture the dynamical behavior of the time series efﬁciently. {DNS} exhibits a substantially improved (≈ 10\% better) performance compared to more complex and resource-intensive state-of-theart algorithms in large scale regression problems. Apart from the traditional Mean Squared Error ({MSE}), we also propose a new Movement Prediction Metric or {MPM} (for detection of lag in time series) as a new complementary performance metric to evaluate the efﬁcacy of {DNS} better.}
      \field{booktitle}{2020 International Joint Conference on Neural Networks ({IJCNN})}
      \field{eventtitle}{2020 International Joint Conference on Neural Networks ({IJCNN})}
      \field{isbn}{978-1-72816-926-2}
      \field{langid}{english}
      \field{month}{7}
      \field{title}{A Dual Network Solution ({DNS}) for Lag-Free Time Series Forecasting}
      \field{urlday}{5}
      \field{urlmonth}{8}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 8}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/IJCNN48605.2020.9207022
      \endverb
      \verb{file}
      \verb Samanta et al. - 2020 - A Dual Network Solution (DNS) for Lag-Free Time Se.pdf:/Users/sharmaparth/Zotero/storage/QSGFIIE4/Samanta et al. - 2020 - A Dual Network Solution (DNS) for Lag-Free Time Se.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9207022/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9207022/
      \endverb
    \endentry
    \entry{yahoo_nifty50_history}{online}{}
      \name{author}{1}{}{%
        {{hash=866e8d567dd5e253610d253b71b7450e}{%
           family={{Yahoo Finance}},
           familyi={Y\bibinitperiod}}}%
      }
      \strng{namehash}{866e8d567dd5e253610d253b71b7450e}
      \strng{fullhash}{866e8d567dd5e253610d253b71b7450e}
      \strng{bibnamehash}{866e8d567dd5e253610d253b71b7450e}
      \strng{authorbibnamehash}{866e8d567dd5e253610d253b71b7450e}
      \strng{authornamehash}{866e8d567dd5e253610d253b71b7450e}
      \strng{authorfullhash}{866e8d567dd5e253610d253b71b7450e}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{Accessed: May 20, 2025}
      \field{title}{{NIFTY 50 (\textasciicircum NSEI) Historical Data}}
      \field{year}{2025}
      \verb{urlraw}
      \verb https://finance.yahoo.com/quote/%5ENSEI/history/
      \endverb
      \verb{url}
      \verb https://finance.yahoo.com/quote/%5ENSEI/history/
      \endverb
    \endentry
    \entry{nse_vix}{online}{}
      \name{author}{1}{}{%
        {{hash=31eb890329278c2ccdacdfa3aaf99ca8}{%
           family={{National Stock Exchange of India}},
           familyi={N\bibinitperiod}}}%
      }
      \strng{namehash}{31eb890329278c2ccdacdfa3aaf99ca8}
      \strng{fullhash}{31eb890329278c2ccdacdfa3aaf99ca8}
      \strng{bibnamehash}{31eb890329278c2ccdacdfa3aaf99ca8}
      \strng{authorbibnamehash}{31eb890329278c2ccdacdfa3aaf99ca8}
      \strng{authornamehash}{31eb890329278c2ccdacdfa3aaf99ca8}
      \strng{authorfullhash}{31eb890329278c2ccdacdfa3aaf99ca8}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{Accessed: May 16, 2025}
      \field{title}{Historical Volatility Index (VIX) Reports}
      \field{year}{2024}
      \verb{urlraw}
      \verb https://www.nseindia.com/reports-indices-historical-vix
      \endverb
      \verb{url}
      \verb https://www.nseindia.com/reports-indices-historical-vix
      \endverb
    \endentry
    \entry{staudemeyer_understanding_2019}{article}{}
      \name{author}{2}{}{%
        {{hash=ca20c4cfdf776c7f6192e5d69e4473e5}{%
           family={Staudemeyer},
           familyi={S\bibinitperiod},
           given={Ralf\bibnamedelima C.},
           giveni={R\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
        {{hash=e1e7bd4c33e3dc907948952e5202a2f4}{%
           family={Rothstein\bibnamedelima Morris},
           familyi={R\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{cf2f6ce66886fdd83f2867581d0809cb}
      \strng{fullhash}{cf2f6ce66886fdd83f2867581d0809cb}
      \strng{bibnamehash}{cf2f6ce66886fdd83f2867581d0809cb}
      \strng{authorbibnamehash}{cf2f6ce66886fdd83f2867581d0809cb}
      \strng{authornamehash}{cf2f6ce66886fdd83f2867581d0809cb}
      \strng{authorfullhash}{cf2f6ce66886fdd83f2867581d0809cb}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) are one of the most powerful dynamic classifiers publicly known. The network itself and the related learning algorithms are reasonably well documented to get an idea how it works. This paper will shed more light into understanding how LSTM-RNNs evolved and why they work impressively well, focusing on the early, ground-breaking publications. We significantly improved documentation and fixed a number of errors and inconsistencies that accumulated in previous publications. To support understanding we as well revised and unified the notation used.}
      \field{eprintclass}{cs.NE}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv preprint arXiv:1909.09586}
      \field{note}{42 pages, 11 figures, tutorial}
      \field{title}{Understanding {LSTM} -- A Tutorial into Long Short-Term Memory Recurrent Neural Networks}
      \field{year}{2019}
      \verb{eprint}
      \verb 1909.09586
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.48550/arXiv.1909.09586
      \endverb
      \verb{url}
      \verb https://doi.org/10.48550/arXiv.1909.09586
      \endverb
      \keyw{Neural and Evolutionary Computing,Computation and Language,Machine Learning}
    \endentry
    \entry{9998301}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=0f5d23d681da576bb41893423887d1af}{%
           family={Atabay},
           familyi={A\bibinitperiod},
           given={Fj\bibnamedelima Vincent},
           giveni={F\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=6e0336c0a7543eeefde0d71ba9f524a7}{%
           family={Pagkalinawan},
           familyi={P\bibinitperiod},
           given={Ryu\bibnamedelima Mendoza},
           giveni={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=8fadc914178499d70d670efa76e49418}{%
           family={Pajarillo},
           familyi={P\bibinitperiod},
           given={Steven\bibnamedelima Dale},
           giveni={S\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=b9b9210c93425a5aff949068a44a92ca}{%
           family={Villanueva},
           familyi={V\bibinitperiod},
           given={Alonica\bibnamedelima R.},
           giveni={A\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=20defeb4bd1dd7e0f016ebb75947d9c6}{%
           family={Taylar},
           familyi={T\bibinitperiod},
           given={Jonathan\bibnamedelima V.},
           giveni={J\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \strng{namehash}{ddba07fffcbc6a94d0897ce727ef5669}
      \strng{fullhash}{2fbf54fe8a74c18ff0dfc4e1b71b4111}
      \strng{bibnamehash}{2fbf54fe8a74c18ff0dfc4e1b71b4111}
      \strng{authorbibnamehash}{2fbf54fe8a74c18ff0dfc4e1b71b4111}
      \strng{authornamehash}{ddba07fffcbc6a94d0897ce727ef5669}
      \strng{authorfullhash}{2fbf54fe8a74c18ff0dfc4e1b71b4111}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{2022 3rd International Informatics and Software Engineering Conference (IISEC)}
      \field{title}{Multivariate Time Series Forecasting using ARIMAX, SARIMAX, and RNN-based Deep Learning Models on Electricity Consumption}
      \field{year}{2022}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/IISEC56263.2022.9998301
      \endverb
      \keyw{Deep learning;COVID-19;Training;Energy consumption;Time series analysis;Predictive models;Data models;Energy Consumption;Multivariate Time Series;Forecasting;Deep Learning Models}
    \endentry
    \entry{BOLLERSLEV1986307}{article}{}
      \name{author}{1}{}{%
        {{hash=39f8f5a428abd62057a0152546172106}{%
           family={Bollerslev},
           familyi={B\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{39f8f5a428abd62057a0152546172106}
      \strng{fullhash}{39f8f5a428abd62057a0152546172106}
      \strng{bibnamehash}{39f8f5a428abd62057a0152546172106}
      \strng{authorbibnamehash}{39f8f5a428abd62057a0152546172106}
      \strng{authornamehash}{39f8f5a428abd62057a0152546172106}
      \strng{authorfullhash}{39f8f5a428abd62057a0152546172106}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A natural generalization of the ARCH (Autoregressive Conditional Heteroskedastic) process introduced in Engle (1982) to allow for past conditional variances in the current conditional variance equation is proposed. Stationarity conditions and autocorrelation structure for this new class of parametric models are derived. Maximum likelihood estimation and testing are also considered. Finally an empirical example relating to the uncertainty of the inflation rate is presented.}
      \field{issn}{0304-4076}
      \field{journaltitle}{Journal of Econometrics}
      \field{number}{3}
      \field{title}{Generalized autoregressive conditional heteroskedasticity}
      \field{volume}{31}
      \field{year}{1986}
      \field{pages}{307\bibrangedash 327}
      \range{pages}{21}
      \verb{doi}
      \verb https://doi.org/10.1016/0304-4076(86)90063-1
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/0304407686900631
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/0304407686900631
      \endverb
    \endentry
    \entry{breiman2001random}{article}{}
      \name{author}{1}{}{%
        {{hash=132b7100417675d55d5d4d8b244f7a34}{%
           family={Breiman},
           familyi={B\bibinitperiod},
           given={Leo},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{fullhash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{bibnamehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{authorbibnamehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{authornamehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{authorfullhash}{132b7100417675d55d5d4d8b244f7a34}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.}
      \field{issn}{1573-0565}
      \field{journaltitle}{Machine Learning}
      \field{number}{1}
      \field{title}{Random Forests}
      \field{volume}{45}
      \field{year}{2001}
      \field{pages}{5\bibrangedash 32}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1023/A:1010933404324
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1023/A:1010933404324
      \endverb
      \verb{url}
      \verb https://doi.org/10.1023/A:1010933404324
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

